Hazm
====
![Tests](https://img.shields.io/github/actions/workflow/status/roshan-research/hazm/tests.yml?branch=master)
![PyPI - Downloads](https://img.shields.io/github/downloads/roshan-research/hazm/total)
![GitHub](https://img.shields.io/github/license/roshan-research/hazm)

Python library for digesting Persian text.
+ Text cleaning
+ Sentence and word tokenizer
+ Word lemmatizer
+ POS tagger
+ Shallow parser
+ Dependency parser
+ Interfaces for Persian corpora
+ [NLTK](http://nltk.org/) compatible
+ Python 2.7, 3.4, 3.5, 3.6, 3.7 and 3.8 support

## Documentation
Visit https://roshan-ai.ir/hazm/docs to view the full documentation.

## Precisions

The `Chunker` and `Lemmatizer` as surface analyzers have a precision of 89.9%. Also, `POSTagger` and `DependencyParser` as morphological taggers, have a precision of 97.1%.

|**Module name**       |**Precision**   |
|----------------------|----------------|
| **Lemmatizer**       | 89.9%          |
| **Chunker**          | 89.9%          |
| **POSTagger**        | 97.1%          |
| **DependencyParser** | 97.1%          |


## Usage

```python
>>> from __future__ import unicode_literals
>>> from hazm import *

>>> normalizer = Normalizer()
>>> normalizer.normalize('Ø§ØµÙ„Ø§Ø­ Ù†ÙˆÙŠØ³Ù‡ Ù‡Ø§ Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†ÛŒÙ…â€ŒÙØ§ØµÙ„Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø§ Ø¢Ø³Ø§Ù† Ù…ÙŠ ÙƒÙ†Ø¯')
'Ø§ØµÙ„Ø§Ø­ Ù†ÙˆÛŒØ³Ù‡â€ŒÙ‡Ø§ Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†ÛŒÙ…â€ŒÙØ§ØµÙ„Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø§ Ø¢Ø³Ø§Ù† Ù…ÛŒâ€ŒÚ©Ù†Ø¯'

>>> sent_tokenize('Ù…Ø§ Ù‡Ù… Ø¨Ø±Ø§ÛŒ ÙˆØµÙ„ Ú©Ø±Ø¯Ù† Ø¢Ù…Ø¯ÛŒÙ…! ÙˆÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ØŒ Ø¬Ø¯Ø§ Ø¨Ù‡ØªØ± Ù†ÛŒØ³ØªØŸ')
['Ù…Ø§ Ù‡Ù… Ø¨Ø±Ø§ÛŒ ÙˆØµÙ„ Ú©Ø±Ø¯Ù† Ø¢Ù…Ø¯ÛŒÙ…!', 'ÙˆÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ØŒ Ø¬Ø¯Ø§ Ø¨Ù‡ØªØ± Ù†ÛŒØ³ØªØŸ']
>>> word_tokenize('ÙˆÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ØŒ Ø¬Ø¯Ø§ Ø¨Ù‡ØªØ± Ù†ÛŒØ³ØªØŸ')
['ÙˆÙ„ÛŒ', 'Ø¨Ø±Ø§ÛŒ', 'Ù¾Ø±Ø¯Ø§Ø²Ø´', 'ØŒ', 'Ø¬Ø¯Ø§', 'Ø¨Ù‡ØªØ±', 'Ù†ÛŒØ³Øª', 'ØŸ']

>>> stemmer = Stemmer()
>>> stemmer.stem('Ú©ØªØ§Ø¨â€ŒÙ‡Ø§')
'Ú©ØªØ§Ø¨'
>>> lemmatizer = Lemmatizer()
>>> lemmatizer.lemmatize('Ù…ÛŒâ€ŒØ±ÙˆÙ…')
'Ø±ÙØª#Ø±Ùˆ'

>>> tagger = POSTagger(model='resources/postagger.model')
>>> tagger.tag(word_tokenize('Ù…Ø§ Ø¨Ø³ÛŒØ§Ø± Ú©ØªØ§Ø¨ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†ÛŒÙ…'))
[('Ù…Ø§', 'PRO'), ('Ø¨Ø³ÛŒØ§Ø±', 'ADV'), ('Ú©ØªØ§Ø¨', 'N'), ('Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†ÛŒÙ…', 'V')]

>>> chunker = Chunker(model='resources/chunker.model')
>>> tagged = tagger.tag(word_tokenize('Ú©ØªØ§Ø¨ Ø®ÙˆØ§Ù†Ø¯Ù† Ø±Ø§ Ø¯ÙˆØ³Øª Ø¯Ø§Ø±ÛŒÙ…'))
>>> tree2brackets(chunker.parse(tagged))
'[Ú©ØªØ§Ø¨ Ø®ÙˆØ§Ù†Ø¯Ù† NP] [Ø±Ø§ POSTP] [Ø¯ÙˆØ³Øª Ø¯Ø§Ø±ÛŒÙ… VP]'

>>> parser = DependencyParser(tagger=tagger, lemmatizer=lemmatizer)
>>> parser.parse(word_tokenize('Ø²Ù†Ú¯â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ú©Ù‡ Ø¨Ù‡ ØµØ¯Ø§ Ø¯Ø±Ù…ÛŒâ€ŒØ¢ÛŒØ¯ØŸ'))
<DependencyGraph with 8 nodes>

```

## Installation
The latest stable version of Hazm can be installed through `pip`:

	pip install hazm

But for testing or using Hazm with the latest updates you may use:

	pip install https://github.com/roshan-research/hazm/archive/master.zip --upgrade

We have also trained [tagger and parser models](https://github.com/roshan-research/hazm/releases/download/v0.5/resources-0.5.zip). You may put these models in the `resources` folder of your project.

## Extensions

Note: These are not official versions of hazm, not uptodate on functionality and are not supported by Roshan.

+ [**JHazm**](https://github.com/mojtaba-khallash/JHazm): A Java port of Hazm
+ [**NHazm**](https://github.com/mojtaba-khallash/NHazm): A C# port of Hazm

## Contribution

We welcome and appreciate any contributions to this repo, such as bug reports, feature requests, code improvements, documentation updates, etc. Please follow the [coding guideline](./CODING.md) when contributing. You can open an issue, fork the repo, write your code, create a pull request and wait for a review and feedback. Thank you for your interest and support in this repo! 

We look forward to collaborating with you! ðŸ˜Š

## Thanks

+ to constributors: [Mojtaba Khallash](https://github.com/mojtaba-khallash) and [Mohsen Imany](https://github.com/imani).
+ to [Virastyar](http://virastyar.ir/) project for persian word list.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=roshan-research/hazm&type=Date)](https://star-history.com/#roshan-research/hazm&Date)
